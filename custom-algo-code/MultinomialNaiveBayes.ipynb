{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "import codecs\n",
    "import string\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_paths(folder_name):\n",
    "    \"\"\" folder name: string representing the data folder name\n",
    "        Y : list of string, stores newsgroup names, used as classes\n",
    "        returns list of paths to the documents and Y\n",
    "    \"\"\"\n",
    "    \"\"\"      |<-----Absolute Path------>|        \"\"\"\n",
    "    prefix = \"C:\\\\Users\\\\Acer\\\\Desktop\\\\project\\\\\" #--------------------------> store (the absolute/relative path to the dir where the folder is) as prefix \n",
    "    path = prefix + folder_name #------------------------------------> path to the folder\n",
    "    newsgroups = os.listdir(path) #----------------------------------> path list of newsgroups which has all the docs\n",
    "    path_list = [] #-------------------------------------------------> stores the path list to docs (not seperated by newsgroups)\n",
    "    Y = [] #---------------------------------------------------------> stores newsgroup name corresponding to path_list\n",
    "    for news_group in newsgroups:\n",
    "        files_path = path + \"\\\\\" + news_group #----------------------> path to the documents inside a newsgroup\n",
    "        files = os.listdir(files_path) #-----------------------------> retrieving the documents inside the newsgroup\n",
    "        Y += ([news_group]*len(files)) #-----------------------------> all the class name would be same for every docs inside a newsgroup\n",
    "        for file in files:\n",
    "            path_list.append(files_path+\"\\\\\"+file) #-----------------> appends path to a single doc to the path_list\n",
    "    return path_list, Y #--------------------------------------------> (paths to data docs, output_classes)\n",
    "    \n",
    "    \n",
    "def remove_metadata(lines_list):\n",
    "    \"\"\" seperates the file into lists of lines\n",
    "        filters out the lines having ['Xref','Path','Date'] headers as its not important\n",
    "        (I should have filtered out the 'From' header too, but I thought the sender name might help classifying the data)\n",
    "        returns the filtered list of lines\n",
    "    \"\"\"\n",
    "    new_lines = [] #-------------------------------------------------> list of lines without unimportant headers\n",
    "    for lines in lines_list:\n",
    "        lines = lines.split('\\n')\n",
    "        for line in lines:\n",
    "            if line[:4] in ['Xref','Path','Date']:\n",
    "                continue #-------------------------------------------> skipping certain headers\n",
    "            new_lines.append(line)\n",
    "            \n",
    "    return new_lines #-----------------------------------------------> filtered list of lines\n",
    "\n",
    "\n",
    "def extract_words(line):\n",
    "    \"\"\" splits the word with separators [\"-\", ',', ' ', '.', '@', '\\t'] then cleans and processes the words\n",
    "        line : string -> represents particular line of the current doc\n",
    "    \"\"\"\n",
    "    words = re.split(r'[-,\\s.@\\t]\\s*', line.strip()) #---------------> split operation\n",
    "    words = preprocess(words) #--------------------------------------> processing\n",
    "    words = remove_stopwords(words) #--------------------------------> removing unimportant words\n",
    "    \n",
    "    return words #---------------------------------------------------> list of cleaned words\n",
    "\n",
    "\n",
    "def read_text(path):\n",
    "    \"\"\" reads the text of a single document and converts the text as list of words\n",
    "        path: string represents the path to a particular document\n",
    "    \"\"\"\n",
    "    f = open(path, 'r') \n",
    "    text_lines = f.readlines() #------------------------------------> load document as a list of lines\n",
    "    text_lines = remove_metadata(text_lines) #----------------------> removing the meta-data at the top of each document\n",
    "    doc_words = [] # -----------------------------------------------> initiazing an array to hold all the words in a document\n",
    "    \"\"\"traverse over all the lines and tokenize each one with the help of helper function: extract_words\"\"\"\n",
    "    for line in text_lines:\n",
    "        words = (extract_words(line)) #-----------------------------> stores the cleaned and processed words from line\n",
    "        if words != ['']:\n",
    "            doc_words += words #------------------------------------> adding list of words into the total collection without increasing the dimension\n",
    "    return doc_words \n",
    "\n",
    "\n",
    "def create_XY(folder_name):\n",
    "    \"\"\" retrieves X, Y from the given folder\"\"\"\n",
    "    paths,Y = file_paths(folder_name) #-----------------------------> storing the path lists to singular docs and respective class name\n",
    "    X = []\n",
    "    for path in paths:\n",
    "        X.append(read_text(path))\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['', 'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at',\n",
    " 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \n",
    " 'can', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during',\n",
    " 'each', 'few', 'for', 'from', 'further',\n",
    " 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\",\n",
    " 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\",\n",
    " 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself',\n",
    " \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself',\n",
    " 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours' 'ourselves', 'out', 'over', 'own',\n",
    " 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', \n",
    " 'than', 'that',\"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \n",
    " \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', \n",
    " 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where',\n",
    " \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\",'will', 'with', \"won't\", 'would', \"wouldn't\", \n",
    " 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', \n",
    " 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'hundred', 'thousand', '1st', '2nd', '3rd',\n",
    " '4th', '5th', '6th', '7th', '8th', '9th', '10th','subject', 'lines', 'newsgroups','sender', 'like','just', 'know', 'get', 'think',\n",
    " 'well', 'now', 'even', 'see', 'way', 'say', 'world', 'make', 'many', 'much', 'right', 'want', 'anyone', 'reply', 'said', 'used',\n",
    " 'need',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(words):\n",
    "#     table = str.maketrans('', '', '\\t')\n",
    "#     words = [word.translate(table) for word in words] \n",
    "    \"\"\" the character: ' appears in a lot of stopwords and changes meaning of words if removed\n",
    "        hence it is removed from the list of symbols that are to be discarded from the documents\n",
    "    \"\"\"\n",
    "    punctuations = (string.punctuation).replace(\"'\", \"\")\n",
    "    trans_table = str.maketrans('', '', punctuations) #-------------------------> mapping of punctuations to \"\"\n",
    "    stripped_words = [word.translate(trans_table) for word in words] #----------> removing puntuations\n",
    "    \n",
    "    words = [str for str in stripped_words if str] #----------> removing empty strings\n",
    "    \n",
    "    \"\"\" some words are quoted in the documents & as we have not removed ' to maintain the integrity of some stopwords\n",
    "        we try to unquote such words below \n",
    "    \"\"\"\n",
    "    p_words = []\n",
    "    for word in words:\n",
    "        if (word[0] and (word[len(word)-1] == \"'\" or word[len(word)-1] == '\"')):\n",
    "            word = word[1:len(word)-1]\n",
    "        elif(word[0] == \"'\" or word[0] == '\"'):\n",
    "            word = word[1:len(word)]\n",
    "        else:\n",
    "            word = word\n",
    "        p_words.append(word)\n",
    "        \n",
    "    \"\"\"remove just-numeric strings as they do not have any significant meaning in text classification\"\"\"\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "    \n",
    "    words = [word.lower() for word in words if len(word) > 2] #------------------> remove words with only 2 characters and transform to lowercase\n",
    "    return words\n",
    "    \n",
    "\n",
    "def remove_stopwords(words):\n",
    "    return [word for word in words if word not in stopwords] #-------------------> just removes the stopwords\n",
    "\n",
    "\n",
    "def flatten(_2d_list):\n",
    "    \"\"\"2d to 1d converter\"\"\"\n",
    "    _1d_list = []\n",
    "    for ele in _2d_list:\n",
    "        _1d_list += ele\n",
    "    return _1d_list\n",
    "\n",
    "\n",
    "def first_n_most_freq(words, n):\n",
    "    \"\"\" function two select words as features based on there frequency \"\"\"\n",
    "    np_list_of_words = np.array(flatten(words)) #--------------------------------> 1d collection of all words\n",
    "    words, counts = np.unique(np_list_of_words, return_counts=True) #------------> stores unique words along with their count\n",
    "    freq, features = (list(i) for i in zip(*(sorted(zip(counts, words), reverse=True)))) #sorting the unique words according to their frequency\n",
    "    \"\"\" I had printed the frequent words and selected unnecessary words manually from the output\n",
    "        appended those words to stopwords and ran the code again\n",
    "        \n",
    "    freq_unnecessary_words = []\n",
    "    for i in range(len(freq)):\n",
    "        if(freq[i]>2000):\n",
    "            freq_unnecessary_words.append(features[i])\n",
    "    print(freq_unnecessary_words)\n",
    "    \"\"\"\n",
    "    return features[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform X {list(list(string)) --> list(list(int))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_transform(X, n):\n",
    "    \"\"\" this function stores counts of words inside a doc(numeric representation) in a dictionary \n",
    "        returns a call to convert_words_to_num\n",
    "        total transformation => a list of (rows having w1,w2,...w*t* words) to a list of (rows having counts of *n* feature words)\n",
    "    \"\"\"\n",
    "    dictionary = {} #---------------------------------------> the dictionary which holds counts of words per document\n",
    "    doc_num = 1 #-------------------------------------------> numeric key representing a doc\n",
    "    for doc_words in X:\n",
    "        #print(doc_words)\n",
    "        np_doc_words = np.asarray(doc_words)\n",
    "        w, c = np.unique(np_doc_words, return_counts=True) #> unique words present inside a doc along with its count\n",
    "        dictionary[doc_num] = {} #--------------------------> creating words: counts dictionary inside the doc key\n",
    "        for i in range(len(w)):\n",
    "            dictionary[doc_num][w[i]] = c[i] #--------------> storing the count of that word\n",
    "        doc_num = doc_num + 1 #-----------------------------> next numeric key representing next doc\n",
    "    return convert_words_to_num(X, dictionary, n)\n",
    "\n",
    "\n",
    "def convert_words_to_num(X, dictionary, n):\n",
    "    X_data = [] #---------------------------------------------> stores transformed X\n",
    "    features = first_n_most_freq(X, n) #----------------------> creating features with n most frequent words\n",
    "    for k in dictionary.keys():\n",
    "        row = [] #--------------------------------------------> stores the counts of every feature-words for a given doc\n",
    "        for f in features:\n",
    "            if(f in dictionary[k].keys()):\n",
    "                \"\"\" if word f is present in the dictionary of the document as a key, its value is copied\n",
    "                    this gives us no. of occurences \"\"\"\n",
    "                row.append(dictionary[k][f]) \n",
    "            else:\n",
    "                row.append(0) #-------------------------------> if not present, the no. of occurences is zero\n",
    "        X_data.append(row)\n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14997 5000\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_XY(\"20_newsgroups\")\n",
    "X = X_transform(X, 5000)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=0)\n",
    "print(len(X_train),len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiNB:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.class_prob = None\n",
    "        self.prior = None\n",
    "        self.likelihood = None\n",
    "    \n",
    "    \n",
    "    def convert(self, Y, classes):\n",
    "        \"\"\" converts Y to list(int) \"\"\"\n",
    "        classes = list(classes)\n",
    "        Y_num = []\n",
    "        for y in Y:\n",
    "            Y_num.append(classes.index(y)) #--------------------------------> inplace of string, it stores the index of that string in self.classes\n",
    "        return Y_num\n",
    "        \n",
    "        \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\" I have used list instead of dict datatype to store my model to decrease look-up time and space complexity,\n",
    "            the probablities(p(y=ai / X=x) and p(y=ai)) are solely based on training data\n",
    "            so, instead of storing the counts, I have directly stored the probablities as prior(stores p(y=ai)) & likelihood(stores p(y=ai / Wj=wj))\n",
    "        \"\"\"\n",
    "        n_docs, n_features = X_train.shape \n",
    "        classes = np.unique(Y_train) #--------------------------------------> names of classes\n",
    "        n_classes = len(classes)\n",
    "        prior = np.zeros(n_classes) #---------------------------------------> initializing prior with zeroes,stores log(p(y=ai))\n",
    "        likelihood = np.zeros((n_features, n_classes)) #--------------------> initializing likelihood with zeroes, stores log(p(y=ai/ Wj= wj))\n",
    "        no_docs_per_class = np.zeros(n_classes) #---------------------------> stores the num of docs per class\n",
    "        no_word_i_per_class = np.zeros((n_classes, n_features)) #-----------> stores the num of occurrence of word_i per class\n",
    "        Y_num = self.convert(Y_train,classes)\n",
    "        \n",
    "        for i in range(n_docs):\n",
    "            class_i = Y_num[i]\n",
    "            no_docs_per_class[class_i] += 1 #-------------------------------> increase the doc count of class_i\n",
    "            for j in range(n_features):\n",
    "                no_word_i_per_class[class_i][j] += X_train[i][j] # ---------> increase word_j count class_i\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            prior[i] = np.log(no_docs_per_class[i]/n_docs) #----------------> p(y=ai) = (num of class_i occurrence)/(total num of docs)\n",
    "            \n",
    "        for i in range(n_features):\n",
    "            for j in range(n_classes):\n",
    "                numerator = (no_word_i_per_class[j][i]+1) #-----------------> n_wi in class_j + 1(laplace correction)\n",
    "                denominator = (no_word_i_per_class[j].sum() + n_features) #-> total num of words in class_j + num of features(laplace correction)\n",
    "                likelihood[i][j]= np.log(numerator/denominator) #-----------> log probablity of class_j given word_i\n",
    "        \n",
    "        \"\"\" saving trained datasets \"\"\"\n",
    "        self.prior = prior\n",
    "        self.likelihood = likelihood\n",
    "        self.n_features = n_features\n",
    "        self.n_docs = n_docs\n",
    "        self.n_classes = n_classes\n",
    "        self.classes = classes\n",
    "        \n",
    "    \n",
    "    def probablity(self, x, class_i):\n",
    "        \"\"\" function to calculate probablity of a class given X=x\"\"\"\n",
    "        output = 0\n",
    "        for j in range(self.n_features):\n",
    "            if x[j]==0:\n",
    "                continue #-------------------------------------------------> skip the word that is not in current doc\n",
    "            output += self.prior[class_i] + self.likelihood[j][class_i] #--> log(p(y=ai)*p(y=ai/Wj=wj)) = log(p(y=ai)) - log(p(y=ai/ Wj= wj))\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def predict_single_point(self, x):\n",
    "        best_p = -100000 #-------------------------------------------------> stores best log probablity\n",
    "        best_class = -1 #--------------------------------------------------> stores the best class index\n",
    "        for class_i in range(self.n_classes):\n",
    "            p_class_i = self.probablity(x, class_i)\n",
    "            if(p_class_i > best_p):\n",
    "                best_p = p_class_i #---------------------------------------> update the current best score\n",
    "                best_class = class_i #-------------------------------------> update the current best class index\n",
    "\n",
    "        return self.classes[best_class] #----------------------------------> return the class name using best class index\n",
    "\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        \"\"\" make prediction for the given dataset using trained model\"\"\"\n",
    "        Y_pred = []\n",
    "        for x in x_test:\n",
    "            y_predicted = self.predict_single_point(x) #-------------------> predict for a single doc\n",
    "            Y_pred.append(y_predicted) #-----------------------------------> append the results\n",
    "\n",
    "        #print(Y_pred)\n",
    "        return Y_pred\n",
    "    \n",
    "    \n",
    "    def accuracy(self, Y_pred, Y_true):\n",
    "        n = len(Y_true) #--------------------------------------------------> total points\n",
    "        m = 0 #------------------------------------------------------------> accurate points\n",
    "        for i in range(n):\n",
    "            if Y_pred[i]==Y_true[i]:\n",
    "                m += 1\n",
    "        return m/n #-------------------------------------------------------> accuracy = accurate points/total points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MultiNB()\n",
    "my_clf.fit(np.array(X_train), Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8964"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_prediction = my_clf.predict(X_test)\n",
    "my_clf.accuracy(my_prediction,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8842"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_clf = MultinomialNB()\n",
    "std_clf.fit(X_train, Y_train)\n",
    "std_prediction = std_clf.predict(X_test)\n",
    "std_clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "My model\n",
      "--------------\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.78      0.85      0.81       233\n",
      "           comp.graphics       0.81      0.87      0.84       253\n",
      " comp.os.ms-windows.misc       0.90      0.79      0.84       249\n",
      "comp.sys.ibm.pc.hardware       0.77      0.90      0.83       240\n",
      "   comp.sys.mac.hardware       0.89      0.90      0.90       236\n",
      "          comp.windows.x       0.88      0.85      0.86       240\n",
      "            misc.forsale       0.90      0.90      0.90       261\n",
      "               rec.autos       0.97      0.95      0.96       269\n",
      "         rec.motorcycles       0.99      0.96      0.98       284\n",
      "      rec.sport.baseball       0.99      0.97      0.98       248\n",
      "        rec.sport.hockey       0.97      1.00      0.98       231\n",
      "               sci.crypt       0.97      0.98      0.97       233\n",
      "         sci.electronics       0.93      0.92      0.93       244\n",
      "                 sci.med       0.98      0.95      0.96       256\n",
      "               sci.space       0.96      0.96      0.96       246\n",
      "  soc.religion.christian       0.96      1.00      0.98       252\n",
      "      talk.politics.guns       0.84      0.92      0.88       249\n",
      "   talk.politics.mideast       0.94      0.94      0.94       281\n",
      "      talk.politics.misc       0.78      0.73      0.76       259\n",
      "      talk.religion.misc       0.70      0.56      0.62       236\n",
      "\n",
      "                accuracy                           0.90      5000\n",
      "               macro avg       0.90      0.90      0.89      5000\n",
      "            weighted avg       0.90      0.90      0.90      5000\n",
      "\n",
      "\n",
      "confusion_matrix\n",
      "\n",
      "[[199   0   0   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    1  31]\n",
      " [  0 220   7  16   2   4   1   0   0   0   0   1   0   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0  14 196  14   2  20   1   0   0   0   0   0   1   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   2   2 215  13   1   4   0   0   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1  16 213   1   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  18  11   4   1 203   1   0   0   0   0   2   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  10   2   0 235   4   0   0   0   1   8   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   1   1   8 256   1   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   3   5 273   0   0   0   0   1   0   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   0   0 240   5   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 230   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   0 229   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   4   0   6   5   0   2   0   0   0   0   1 225   1   0   0   0   0\n",
      "    0   0]\n",
      " [  1   5   0   0   0   0   1   0   1   1   1   0   1 242   2   0   0   1\n",
      "    0   0]\n",
      " [  0   4   0   0   0   0   0   0   0   0   0   0   0   1 237   0   0   0\n",
      "    4   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 252   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0 230   0\n",
      "   12   5]\n",
      " [  1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   3 264\n",
      "   11   1]\n",
      " [  1   0   0   0   0   0   0   0   0   1   0   1   0   0   3   0  28  14\n",
      "  190  21]\n",
      " [ 54   1   0   0   0   0   0   0   0   0   0   0   0   0   0  11  11   2\n",
      "   24 133]]\n",
      "\n",
      "\n",
      "------------\n",
      "Standard model\n",
      "--------------\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.83      0.81       233\n",
      "           comp.graphics       0.81      0.85      0.83       253\n",
      " comp.os.ms-windows.misc       0.87      0.80      0.83       249\n",
      "comp.sys.ibm.pc.hardware       0.73      0.86      0.79       240\n",
      "   comp.sys.mac.hardware       0.85      0.88      0.86       236\n",
      "          comp.windows.x       0.88      0.79      0.83       240\n",
      "            misc.forsale       0.89      0.92      0.90       261\n",
      "               rec.autos       0.95      0.93      0.94       269\n",
      "         rec.motorcycles       0.95      0.97      0.96       284\n",
      "      rec.sport.baseball       0.97      0.96      0.96       248\n",
      "        rec.sport.hockey       0.97      0.99      0.98       231\n",
      "               sci.crypt       0.97      0.97      0.97       233\n",
      "         sci.electronics       0.93      0.85      0.89       244\n",
      "                 sci.med       0.97      0.92      0.94       256\n",
      "               sci.space       0.93      0.96      0.94       246\n",
      "  soc.religion.christian       0.94      1.00      0.97       252\n",
      "      talk.politics.guns       0.83      0.91      0.87       249\n",
      "   talk.politics.mideast       0.94      0.94      0.94       281\n",
      "      talk.politics.misc       0.78      0.75      0.76       259\n",
      "      talk.religion.misc       0.71      0.58      0.64       236\n",
      "\n",
      "                accuracy                           0.88      5000\n",
      "               macro avg       0.88      0.88      0.88      5000\n",
      "            weighted avg       0.88      0.88      0.88      5000\n",
      "\n",
      "\n",
      "confusion_matrix\n",
      "\n",
      "[[193   0   0   0   0   0   0   1   1   0   0   0   2   0   0   2   0   0\n",
      "    1  33]\n",
      " [  0 214  11  15   2   6   2   0   0   0   0   0   0   2   1   0   0   0\n",
      "    0   0]\n",
      " [  0  12 200  16   2  15   1   0   0   0   0   1   1   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   4   5 207  15   2   5   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   1  20 208   0   3   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  20  12   8   3 190   1   0   0   0   0   2   1   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   8   1   0 240   3   1   0   0   0   4   0   1   0   1   0\n",
      "    1   0]\n",
      " [  0   0   1   0   1   0   9 251   3   1   1   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   4   3 276   0   0   0   0   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   0   3   1 237   5   0   0   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   1 228   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   4   0   0   0   2   0   0   0   0   0 225   0   0   0   0   0   0\n",
      "    2   0]\n",
      " [  0   3   1   8  10   0   4   4   0   1   0   1 208   1   3   0   0   0\n",
      "    0   0]\n",
      " [  0   4   0   1   2   1   0   0   5   3   1   0   1 235   2   0   0   1\n",
      "    0   0]\n",
      " [  0   1   0   0   1   0   1   0   1   1   1   0   0   2 235   0   0   0\n",
      "    3   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 252   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   1   0   0   1   0   0   0   0 227   0\n",
      "   13   6]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   6 264\n",
      "    9   1]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   1   0   2   3   0  29  14\n",
      "  193  16]\n",
      " [ 48   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13  12   2\n",
      "   23 138]]\n"
     ]
    }
   ],
   "source": [
    "print(\"------------\\nMy model\\n--------------\\n\\nclassification report:\")\n",
    "print(classification_report(Y_test, my_prediction))\n",
    "print(\"\\nconfusion_matrix\\n\")\n",
    "print(confusion_matrix(Y_test, my_prediction))\n",
    "\n",
    "print(\"\\n\\n------------\\nStandard model\\n--------------\\n\\nclassification report:\")\n",
    "print(classification_report(Y_test, std_prediction))\n",
    "print(\"\\nconfusion_matrix\\n\")\n",
    "print(confusion_matrix(Y_test, std_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
